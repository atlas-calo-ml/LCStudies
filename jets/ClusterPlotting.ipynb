{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset plotting\n",
    "\n",
    "This is a notebook for plotting general dataset kinematics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, glob, uuid\n",
    "import numpy as np\n",
    "import ROOT as rt\n",
    "import uproot as ur\n",
    "from numba import jit\n",
    "from pathlib import Path\n",
    "\n",
    "path_prefix = os.getcwd() + '/../'\n",
    "if(path_prefix not in sys.path): sys.path.append(path_prefix)\n",
    "from util import ml_util as mu # for passing calo images to regression networks\n",
    "from util import qol_util as qu # for progress bar\n",
    "from util import jet_util as ju"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotstyle = qu.PlotStyle('dark')\n",
    "plotstyle.SetStyle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting average images.\n",
    "\n",
    "Let's plot average cluster images, from two different datasets.\n",
    "\n",
    "Specifically, as one of our datasets contains *labeled* topo-clusters and the other contains *unlabeled* topo-clusters, we're going to apply some classifier and then consider its output categories. This way everything is compared on an equal footing. We want to see if there are noticeable differences between images in our training/calibration dataset (single pions), and our dijet samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Calorimeter meta-data -----\n",
    "layers = [\"EMB1\", \"EMB2\", \"EMB3\", \"TileBar0\", \"TileBar1\", \"TileBar2\"]\n",
    "nlayers = len(layers)\n",
    "cell_size_phi = [0.098, 0.0245, 0.0245, 0.1, 0.1, 0.1]\n",
    "cell_size_eta = [0.0031, 0.025, 0.05, 0.1, 0.1, 0.2]\n",
    "len_phi = [4, 16, 16, 4, 4, 4]\n",
    "len_eta = [128, 16, 8, 4, 4, 2]\n",
    "assert(len(len_phi) == nlayers)\n",
    "assert(len(len_eta) == nlayers)\n",
    "meta_data = {\n",
    "    layers[i]:{\n",
    "        'cell_size':(cell_size_eta[i],cell_size_phi[i]),\n",
    "        'dimensions':(len_eta[i],len_phi[i])\n",
    "    }\n",
    "    for i in range(nlayers)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "data_dir = {\n",
    "    'pion':path_prefix + 'data/pion',\n",
    "    'jet' :path_prefix + 'data/jet'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_name = 'ClusterTree'\n",
    "data_files = {key:glob.glob(val + '/*.root') for key,val in data_dir.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debugging\n",
    "#data_files['jet'] = data_files['jet'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trees = {\n",
    "    key:[ur.open(x)[tree_name] for x in val]\n",
    "    for key,val in data_files.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load calo image for both datasets into a dictionary, for easy access\n",
    "\n",
    "l = len(data_files.keys()) * len(layers)\n",
    "prefix = 'Loading calo images:'\n",
    "suffix = 'Complete'\n",
    "bl = 50\n",
    "i = 0\n",
    "qu.printProgressBarColor(i, l, prefix=prefix, suffix=suffix, length=bl)\n",
    "    \n",
    "calo_images = {}\n",
    "for key, trees in data_trees.items():\n",
    "    calo_images[key] = {}\n",
    "    for layer in layers:\n",
    "        calo_images[key][layer] = np.row_stack([tree.array(layer) for tree in trees])\n",
    "        i+=1\n",
    "        qu.printProgressBarColor(i, l, prefix=prefix, suffix=suffix, length=bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also load the topo-cluster energies, for making cuts\n",
    "eng_calib_tot = {key: np.concatenate([tree.array('cluster_ENG_CALIB_TOT') for tree in trees]) \n",
    "                 for key,trees in data_trees.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to compute network scores (classification) for the topo-clusters. We'll pick clusters that have a very high or very low score (i.e. ones whose identities we are relatively confident about)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and setup for TensorFlow and Keras.\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # disable some of the tensorflow info printouts, only display errors\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ngpu = 1\n",
    "gpu_list = [\"/gpu:\"+str(i) for i in range(ngpu)]\n",
    "strategy = tf.distribute.MirroredStrategy(devices=gpu_list)\n",
    "ngpu = strategy.num_replicas_in_sync\n",
    "print ('Number of devices: {}'.format(ngpu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_dir = path_prefix + 'classifier/Models/pion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_models = {}\n",
    "# flat classifiers\n",
    "print('Loading flat classification models... ')\n",
    "flat_model_files = glob.glob(classification_dir + '/flat/' + '*.h5')\n",
    "flat_model_files.sort()\n",
    "flat_model_names = []\n",
    "for model in flat_model_files:\n",
    "    model_name = model.split('model_')[-1].split('_flat')[0]\n",
    "    print('\\tLoading ' + model_name + '... ',end='')\n",
    "    flat_model_names.append(model_name)\n",
    "    network_models[model_name] = tf.keras.models.load_model(model)\n",
    "    print('Done.')\n",
    "\n",
    "# combo classifier\n",
    "print('Loading simple combo classification model... ',end='')\n",
    "combo_model_file = classification_dir + '/simple/' + 'model_simple_do20.h5'\n",
    "network_models['combo'] = tf.keras.models.load_model(combo_model_file)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute scores. Note that this involves using the calorimeter images, but in a slightly different format than above. We can get the right shape by using `mu.setupCells()`, or by simply flattening our existing images (so that they go from 3D arrays to 2D arrays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(data_trees) * (3 + len(layers))\n",
    "prefix = 'Evaluating classification network:'\n",
    "suffix = 'Complete'\n",
    "bl = 50\n",
    "i = 0\n",
    "qu.printProgressBarColor(i, l, prefix=prefix, suffix=suffix, length=bl)\n",
    " \n",
    "scores = {}\n",
    "for key in data_trees.keys():\n",
    "    combined_images = np.concatenate([calo_images[key][layer].reshape(calo_images[key][layer].shape[0],-1) for layer in layers],axis=1)\n",
    "    i += 1\n",
    "    qu.printProgressBarColor(i, l, prefix=prefix, suffix=suffix, length=bl)\n",
    "    s_combined = mu.standardCells(combined_images, layers)[0]\n",
    "    i += 1\n",
    "    qu.printProgressBarColor(i, l, prefix=prefix, suffix=suffix, length=bl)\n",
    "    \n",
    "    del combined_images\n",
    "    \n",
    "    flat_scores = {}\n",
    "    for layer in layers:\n",
    "        model = network_models[layer]\n",
    "        flat_scores[layer] = model.predict(calo_images[key][layer].reshape(calo_images[key][layer].shape[0],-1))[:,1]\n",
    "        i += 1\n",
    "        qu.printProgressBarColor(i, l, prefix=prefix, suffix=suffix, length=bl)\n",
    "    \n",
    "    model = network_models['combo']\n",
    "    input_scores = np.column_stack([flat_scores[layer] for layer in layers])\n",
    "    del flat_scores\n",
    "    scores[key] = model.predict(input_scores)[:,1] # likelihood of being charged pion (versus neutral pion)\n",
    "    i += 1\n",
    "    qu.printProgressBarColor(i, l, prefix=prefix, suffix=suffix, length=bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt.gStyle.SetOptStat(0)\n",
    "c = rt.TCanvas(qu.RN(),'score',800,600)\n",
    "\n",
    "h = {key:rt.TH1F(qu.RN(), ';Classification Score;Count',100,0.,1.) for key in scores.keys()}\n",
    "colors = {'pion':rt.kBlue,'jet':rt.kRed}\n",
    "\n",
    "for key,hist in h.items(): \n",
    "    hist.SetLineColorAlpha(colors[key],0.7)\n",
    "    hist.SetFillColorAlpha(colors[key],0.3)\n",
    "    for element in scores[key]: hist.Fill(element)\n",
    "    hist.Scale(1. / hist.Integral())\n",
    "    \n",
    "hstack = rt.THStack()\n",
    "legend = rt.TLegend(0.7,0.8,0.9,0.9)\n",
    "legend.SetTextColor(plotstyle.text)\n",
    "\n",
    "for key,hist in h.items():\n",
    "    hstack.Add(hist)\n",
    "    legend.AddEntry(hist,key,'f')\n",
    "\n",
    "hstack.Draw('NOSTACK HIST')\n",
    "hstack.SetMaximum(.3)\n",
    "hstack.SetTitle('Classification Scores')\n",
    "hstack.GetXaxis().SetTitle('Classification score')\n",
    "hstack.GetYaxis().SetTitle('Fractional Count')\n",
    "\n",
    "legend.Draw()\n",
    "rt.gPad.SetLogy()\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each dataset, let's define indices of clusters in which we're interested. To free up some memory -- in case that's a concern at this point -- we can drop events that don't pass our classification score selection.\n",
    "\n",
    "We will pick clusters with very low or high scores, as these are the clusters of whose identities our classification network is most sure. Note that the distributions are rather different between datasets -- our classification is reporting a higher proportion of likely neutral pions in the `pion` dataset than in our `jet` dataset.\n",
    "\n",
    "Note that we will also want to compare the datasets within some relatively narrow band of energies, as their energy distributions will likely be quite different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt.gStyle.SetOptStat(0)\n",
    "c = rt.TCanvas(qu.RN(),'score',800,600)\n",
    "\n",
    "h = {key:rt.TH1F(qu.RN(), ';E_{calib}^{tot};Count',100,0.,100.) for key in scores.keys()}\n",
    "colors = {'pion':rt.kBlue,'jet':rt.kRed}\n",
    "\n",
    "for key,hist in h.items(): \n",
    "    hist.SetLineColorAlpha(colors[key],0.7)\n",
    "    hist.SetFillColorAlpha(colors[key],0.3)\n",
    "    for element in eng_calib_tot[key]: hist.Fill(element)\n",
    "    hist.Scale(1. / hist.Integral())\n",
    "    \n",
    "hstack = rt.THStack()\n",
    "legend = rt.TLegend(0.7,0.8,0.9,0.9)\n",
    "legend.SetTextColor(plotstyle.text)\n",
    "\n",
    "for key,hist in h.items():\n",
    "    hstack.Add(hist)\n",
    "    legend.AddEntry(hist,key,'f')\n",
    "\n",
    "hstack.Draw('NOSTACK HIST')\n",
    "hstack.SetMaximum(.9)\n",
    "hstack.SetTitle('Topo-cluster Truth Energy')\n",
    "hstack.GetXaxis().SetTitle('E_{calib}^{tot} [GeV]')\n",
    "hstack.GetYaxis().SetTitle('Fractional Count')\n",
    "\n",
    "legend.Draw()\n",
    "rt.gPad.SetLogy()\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_threshold = 0.05 # take clusters with score< score_threshold, OR score > 1. - score_threshold\n",
    "energy_window = (9.,10.) # GeV\n",
    "\n",
    "#TODO: Use energy window cut in cluster_indices\n",
    "\n",
    "cluster_indices = {}\n",
    "for key in scores.keys():\n",
    "    \n",
    "    energy_selection = (eng_calib_tot[key] > energy_window[0]) * (eng_calib_tot[key] < energy_window[1])\n",
    "    score_selection  = (scores[key] < score_threshold) + (scores[key] > 1. - score_threshold)\n",
    "    combined_selection = energy_selection * score_selection\n",
    "    cluster_indices[key] = np.where(combined_selection)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply our cluster_indices to the data -- for now we make new variables instead of overwriting\n",
    "calo_images_selected = {key:{\n",
    "    layer:images[cluster_indices[key]]\n",
    "    for layer,images in val.items()\n",
    "    }\n",
    "for key,val in calo_images.items()\n",
    "}\n",
    "\n",
    "eng_calib_tot_selected = {key:val[cluster_indices[key]] for key,val in eng_calib_tot.items()}\n",
    "scores_selected = {key:val[cluster_indices[key]] for key,val in scores.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charged_indices = {key:np.where(scores_selected[key] > 1. - score_threshold)[0] for key in scores.keys()}\n",
    "neutral_indices = {key:np.where(scores_selected[key] < score_threshold)[0] for key in scores.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each calo layer, we want to compare images from the two datasets. So we will make average images for each dataset, as well as the difference between the averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Image2Arrays is broken. \n",
    "@jit\n",
    "def Image2Arrays(image, x_range, y_range):\n",
    "    nx, ny = image.shape\n",
    "    dx = (x_range[1] - x_range[0]) / nx\n",
    "    dy = (y_range[1] - y_range[0]) / ny\n",
    "    \n",
    "    # list of bin centers in x, y\n",
    "    x_vals = np.linspace(x_range[0] + dx/2, x_range[1] - dx/2, nx)\n",
    "    y_vals = np.linspace(y_range[0] + dy/2, y_range[1] - dy/2, ny)\n",
    "    \n",
    "    # now get full list of x,y and w (weights)\n",
    "    x = np.repeat(x_vals,ny).reshape(-1,ny).T.flatten() # like np.tile() but numba-friendly\n",
    "    y = np.repeat(y_vals,nx)\n",
    "    w = image.flatten()\n",
    "    return x,y,w\n",
    "\n",
    "def FillImage(h, image, x_range, y_range, upper=True):\n",
    "    \n",
    "    if(upper): image = np.flip(image,axis=0)\n",
    "    x,y,w = Image2Arrays(image, x_range, y_range)\n",
    "    N = len(x)\n",
    "    for i in range(N):\n",
    "        h.Fill(x[i],y[i],w[i])\n",
    "    \n",
    "    if(np.sum(w) != 0.):\n",
    "        \n",
    "        if(np.random.rand() > 0.95):\n",
    "            a = np.column_stack((x,y,w))\n",
    "            print('\\n')\n",
    "            for entry in a: print(entry)\n",
    "            print('\\n\\n')\n",
    "            for row in image: print(row)\n",
    "            print('---------')\n",
    "   \n",
    "    h.FillN(N,x.astype('float'),y.astype('float'),w.astype('float'))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenience function\n",
    "\n",
    "def ImageDraw(h,N,plot_min,plot_max,n_eta,n_phi):\n",
    "    h.Scale(1./N)\n",
    "    h.Draw('COLZ')\n",
    "    h.SetMinimum(plot_min)\n",
    "    h.SetMaximum(plot_max)\n",
    "    \n",
    "    if(n_eta > 32): n_eta = int(n_eta / 16)\n",
    "    elif(n_eta > 8): n_eta = int(n_eta / 4)\n",
    "    if(n_phi > 8): n_phi = int(n_phi / 4)\n",
    "    \n",
    "    h.GetXaxis().SetNdivisions(-n_eta)\n",
    "    h.GetYaxis().SetNdivisions(-n_phi)\n",
    "    \n",
    "    rt.gPad.SetGrid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt.gStyle.SetOptStat(0)\n",
    "rt.gStyle.SetPalette(rt.kTemperatureMap)\n",
    "\n",
    "nx = 3\n",
    "ny = len(layers) * 2\n",
    "plot_size = 500\n",
    "plot_min, plot_max = (0.,0.06)\n",
    "right_margin = 0.15\n",
    "\n",
    "c = rt.TCanvas(qu.RN(),'avg_images', nx * plot_size, ny * plot_size)\n",
    "c.Divide(nx, ny)\n",
    "\n",
    "hists = [] # keep a list of histogram objects\n",
    "\n",
    "for i,layer in enumerate(layers):\n",
    "    \n",
    "    prefix = '{:<9}:'.format(layer)\n",
    "    suffix = 'Complete'\n",
    "    bl = 50\n",
    "    k = 0\n",
    "    l=6\n",
    "    qu.printProgressBarColor(k, l, prefix=prefix, suffix=suffix, length=bl)\n",
    "    \n",
    "    n_eta, n_phi  = meta_data[layer]['dimensions']\n",
    "    dims = (n_eta,n_phi)\n",
    "    csize = meta_data[layer]['cell_size']\n",
    "    \n",
    "    eta_min = - dims[0] * csize[0] / 2\n",
    "    eta_max = - eta_min\n",
    "    eta_range = (eta_min, eta_max)\n",
    "    \n",
    "    phi_min = - dims[1] * csize[1] / 2\n",
    "    phi_max = - phi_min\n",
    "    phi_range = (phi_min, phi_max)\n",
    "    \n",
    "    # --- Neutral pions ---\n",
    "    \n",
    "    # average image for pion dataset\n",
    "    c.cd(1 + 6*i) # 1-indexing for pads\n",
    "    rt.gPad.SetRightMargin(right_margin)\n",
    "    \n",
    "    h1 = rt.TH2F(qu.RN(), layer + '(#pi^{0}, single pion);#eta;#phi',n_eta,eta_min,eta_max,n_phi,phi_min,phi_max)\n",
    "    N = 0\n",
    "    for image in calo_images_selected['pion'][layer][neutral_indices['pion']]:\n",
    "        N += 1\n",
    "        if(np.sum(image) == 0.): continue\n",
    "        [[h1.SetBinContent(i+1,n_phi-j,h1.GetBinContent(i+1,j+1) + image[i,j]) for i in range(n_eta)] for j in range(n_phi)]\n",
    "        #FillImage(h1,image,eta_range,phi_range)\n",
    "    ImageDraw(h1,N,plot_min,plot_max,n_eta,n_phi)\n",
    "    \n",
    "    k += 1\n",
    "    qu.printProgressBarColor(k, l, prefix=prefix, suffix=suffix, length=bl)\n",
    "    \n",
    "    # average image for jet dataset\n",
    "    c.cd(1 + 6*i + 1)\n",
    "    rt.gPad.SetRightMargin(right_margin)\n",
    "\n",
    "    h2 = rt.TH2F(qu.RN(), layer + '(#pi^{0}, djijet);#eta;#phi',dims[0],eta_min,eta_max,dims[1],phi_min,phi_max)\n",
    "    N = 0\n",
    "    for image in calo_images_selected['jet'][layer][neutral_indices['jet']]:\n",
    "        N += 1\n",
    "        if(np.sum(image) == 0.): continue\n",
    "        [[h2.SetBinContent(i+1,n_phi-j,h2.GetBinContent(i+1,j+1) + image[i,j]) for i in range(n_eta)] for j in range(n_phi)]     \n",
    "    ImageDraw(h2,N,plot_min,plot_max,n_eta,n_phi)\n",
    "    \n",
    "    k += 1\n",
    "    qu.printProgressBarColor(k, l, prefix=prefix, suffix=suffix, length=bl)\n",
    "    \n",
    "    # difference between average images, pion - jet\n",
    "    c.cd(1 + 6*i + 2)\n",
    "    rt.gPad.SetRightMargin(right_margin)\n",
    "    \n",
    "    h3 = h1.Clone()\n",
    "    h3.Add(h2, -1.)\n",
    "    h3.SetTitle(layer + '(#pi^{0}, single pion - dijet);#eta;#phi')\n",
    "    ImageDraw(h3,1,-plot_max,plot_max,n_eta,n_phi)\n",
    "    k += 1\n",
    "    qu.printProgressBarColor(k, l, prefix=prefix, suffix=suffix, length=bl)\n",
    "    \n",
    "    hists.append(h1)\n",
    "    hists.append(h2)\n",
    "    hists.append(h3)\n",
    "\n",
    "    # --- Charged pions ---\n",
    "\n",
    "    # average image for pion dataset\n",
    "    c.cd(1 + 6*i + 3) # 1-indexing for pads\n",
    "    rt.gPad.SetRightMargin(right_margin)\n",
    "\n",
    "    h1 = rt.TH2F(qu.RN(), layer + '(#pi^{#pm}, single pion);#eta;#phi',dims[0],eta_min,eta_max,dims[1],phi_min,phi_max)\n",
    "    N = 0\n",
    "    for image in calo_images_selected['pion'][layer][charged_indices['pion']]:\n",
    "        N += 1\n",
    "        if(np.sum(image) == 0.): continue\n",
    "        [[h1.SetBinContent(i+1,n_phi-j,h1.GetBinContent(i+1,j+1) + image[i,j]) for i in range(n_eta)] for j in range(n_phi)]     \n",
    "    ImageDraw(h1,N,plot_min,plot_max,n_eta,n_phi)\n",
    "\n",
    "    k += 1\n",
    "    qu.printProgressBarColor(k, l, prefix=prefix, suffix=suffix, length=bl)\n",
    "    \n",
    "    # average image for jet dataset\n",
    "    c.cd(1 + 6*i + 4)\n",
    "    rt.gPad.SetRightMargin(right_margin)\n",
    "\n",
    "    h2 = rt.TH2F(qu.RN(), layer + '(#pi^{#pm}, djijet);#eta;#phi',dims[0],eta_min,eta_max,dims[1],phi_min,phi_max)\n",
    "    N = 0\n",
    "    for image in calo_images_selected['jet'][layer][charged_indices['jet']]:\n",
    "        N += 1\n",
    "        if(np.sum(image) == 0.): continue\n",
    "        [[h2.SetBinContent(i+1,n_phi-j,h2.GetBinContent(i+1,j+1) + image[i,j]) for i in range(n_eta)] for j in range(n_phi)]     \n",
    "        #FillImage(h2, image, eta_range,phi_range)\n",
    "    ImageDraw(h2,N,plot_min,plot_max,n_eta,n_phi)\n",
    "\n",
    "    k += 1\n",
    "    qu.printProgressBarColor(k, l, prefix=prefix, suffix=suffix, length=bl)\n",
    "    \n",
    "    # difference between average images, pion - jet\n",
    "    c.cd(1 + 6*i + 5)\n",
    "    rt.gPad.SetRightMargin(right_margin)\n",
    "\n",
    "    h3 = h1.Clone()\n",
    "    h3.Add(h2, -1.)\n",
    "    h3.SetTitle(layer + '(#pi^{#pm}, single pion - dijet);#eta;#phi')\n",
    "    ImageDraw(h3,1,-plot_max,plot_max,n_eta,n_phi)\n",
    "    \n",
    "    k += 1\n",
    "    qu.printProgressBarColor(k, l, prefix=prefix, suffix=suffix, length=bl)\n",
    "    \n",
    "    hists.append(h1)\n",
    "    hists.append(h2)\n",
    "    hists.append(h3)\n",
    "    \n",
    "c.Draw()\n",
    "\n",
    "c.SaveAs(path_prefix + 'jets/comparison.png')\n",
    "c.SaveAs(path_prefix + 'jets/comparison.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
